{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.applications import vgg16, vgg19\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralStyler(object):\n",
    "    def __init__(self, content_image_path, style_image_path,\n",
    "                 weights_filepath=None,\n",
    "                 Content_loss_function_weight=1.0, Style_loss_function_weight=0.00001,\n",
    "                 save_every_n_steps=10,\n",
    "                 verbose=False,\n",
    "                 convnet='VGG16',\n",
    "                 content_layer='block5_conv1',\n",
    "                 style_layers=('block1_conv1',\n",
    "                               'block2_conv1',\n",
    "                               'block3_conv1',\n",
    "                               'block4_conv1',\n",
    "                               'block5_conv1')):\n",
    "        \n",
    "\n",
    "        if content_image_path is None:\n",
    "            raise ValueError('Missing content image')\n",
    "        if style_image_path is None:\n",
    "            raise ValueError('Missing style image')\n",
    "        if convnet not in ('VGG16', 'VGG19'):\n",
    "            raise ValueError('Convnet must be one of: VGG16 or VGG19')\n",
    "\n",
    "        self.content_image_path = content_image_path\n",
    "        self.style_image_path = style_image_path\n",
    "\n",
    "        self.Content_loss_function_weight = Content_loss_function_weight\n",
    "        self.Style_loss_function_weight = Style_loss_function_weight\n",
    "        self.save_every_n_steps = save_every_n_steps\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "        self.layers = style_layers if content_layer in style_layers else style_layers + (content_layer,)\n",
    "\n",
    "        self.iteration = 0\n",
    "        self.step = 0\n",
    "        self.styled_image = None\n",
    "\n",
    "        # VGG\n",
    "        print('Using VGG')\n",
    "        if convnet == 'VGG16':\n",
    "            convnet = vgg16.VGG16(include_top=False, weights='imagenet' if weights_filepath is None else None)\n",
    "        else:\n",
    "            convnet = vgg19.VGG19(include_top=False, weights='imagenet' if weights_filepath is None else None)\n",
    "\n",
    "        if weights_filepath is not None:\n",
    "            print('Loading model weights from: %s' % weights_filepath)\n",
    "            convnet.load_weights(filepath=weights_filepath)\n",
    "\n",
    "        # Convnet output function\n",
    "        self.get_convnet_output = K.function(inputs=[convnet.layers[0].input],\n",
    "                                             outputs=[convnet.get_layer(t).output for t in self.layers])\n",
    "\n",
    "        # Load picture image\n",
    "        original_picture_image = imread(content_image_path)\n",
    "\n",
    "        self.image_shape = (original_picture_image.shape[0], original_picture_image.shape[1], 3)\n",
    "        self.e_image_shape = (1,) + self.image_shape\n",
    "        self.picture_image = self.pre_process_image(original_picture_image.reshape(self.e_image_shape).astype(K.floatx()))\n",
    "\n",
    "        print('Loading picture: %s (%dx%d)' % (self.content_image_path,\n",
    "                                               self.picture_image.shape[2],\n",
    "                                               self.picture_image.shape[1]))\n",
    "\n",
    "        picture_tensor = K.variable(value=self.get_convnet_output([self.picture_image])[self.layers.index(content_layer)])\n",
    "\n",
    "        # Load style image\n",
    "        original_style_image = imread(self.style_image_path)\n",
    "\n",
    "        print('Loading style image: %s (%dx%d)' % (self.style_image_path,\n",
    "                                                   original_style_image.shape[1],\n",
    "                                                   original_style_image.shape[0]))\n",
    "\n",
    "        # Check for style image size\n",
    "        if (original_style_image.shape[0] != self.picture_image.shape[1]) or \\\n",
    "                (original_style_image.shape[1] != self.picture_image.shape[2]):\n",
    "            # Resize image\n",
    "            print('Resizing style image to match picture size: (%dx%d)' %\n",
    "                  (self.picture_image.shape[2], self.picture_image.shape[1]))\n",
    "\n",
    "            original_style_image = imresize(original_style_image,\n",
    "                                                 size=(self.picture_image.shape[1], self.picture_image.shape[2]),\n",
    "                                             interp='lanczos')\n",
    "#             original_style_image = original_style_image.resize((170, 170),PIL.Image.BILINEAR)\n",
    "            \n",
    "\n",
    "        self.style_image = self.pre_process_image(original_style_image.reshape(self.e_image_shape).astype(K.floatx()))\n",
    "       \n",
    "    \n",
    "        # Create style tensors\n",
    "        style_outputs = self.get_convnet_output([self.style_image])\n",
    "        style_tensors = [self.gramian(o) for o in style_outputs]\n",
    "\n",
    "        # Compute loss function(s)\n",
    "        print('Compiling loss and gradient functions')\n",
    "\n",
    "        # Picture loss function\n",
    "        picture_loss_function = 0.5 * K.sum(K.square(picture_tensor - convnet.get_layer(content_layer).output))\n",
    "\n",
    "        # Style loss function\n",
    "        style_loss_function = 0.0\n",
    "        style_loss_function_weight = 1.0 / float(len(style_layers))\n",
    "\n",
    "        for i, style_layer in enumerate(style_layers):\n",
    "            style_loss_function += \\\n",
    "                (style_loss_function_weight *\n",
    "                (1.0 / (4.0 * (style_outputs[i].shape[1] ** 2.0) * (style_outputs[i].shape[3] ** 2.0))) *\n",
    "                 K.sum(K.square(style_tensors[i] - self.gramian(convnet.get_layer(style_layer).output))))\n",
    "\n",
    "        # Composite loss function\n",
    "        composite_loss_function = (self.Content_loss_function_weight * picture_loss_function) + \\\n",
    "                                  (self.Style_loss_function_weight * style_loss_function)\n",
    "\n",
    "        loss_function_inputs = [convnet.get_layer(l).output for l in self.layers]\n",
    "        loss_function_inputs.append(convnet.layers[0].input)\n",
    "\n",
    "        self.loss_function = K.function(inputs=loss_function_inputs,\n",
    "                                        outputs=[composite_loss_function])\n",
    "\n",
    "        # Composite loss function gradient\n",
    "        loss_gradient = K.gradients(loss=composite_loss_function, variables=[convnet.layers[0].input])\n",
    "\n",
    "        self.loss_function_gradient = K.function(inputs=[convnet.layers[0].input],\n",
    "                                                 outputs=loss_gradient)\n",
    "\n",
    "    def fit(self, iterations=10, canvas='random', canvas_image_filepath=None, optimization_method='CG'):\n",
    "\n",
    "        if canvas not in ('random', 'random_from_style', 'random_from_picture', 'style', 'picture', 'custom'):\n",
    "            raise ValueError('Canvas must be one of: random, random_from_style, '\n",
    "                             'random_from_picture, style, picture, custom')\n",
    "\n",
    "        # Generate random image\n",
    "        if canvas == 'random':\n",
    "            self.styled_image = self.pre_process_image(np.random.uniform(0, 256,\n",
    "                                                                         size=self.e_image_shape).astype(K.floatx()))\n",
    "        elif canvas == 'style':\n",
    "            self.styled_image = self.style_image.copy()\n",
    "        elif canvas == 'picture':\n",
    "            self.styled_image = self.picture_image.copy()\n",
    "        elif canvas == 'custom':\n",
    "            self.styled_image = self.pre_process_image(imread(canvas_image_filepath).\n",
    "                                                       reshape(self.e_image_shape).astype(K.floatx()))\n",
    "        else:\n",
    "            self.styled_image = np.ndarray(shape=self.e_image_shape)\n",
    "\n",
    "            for x in range(self.picture_image.shape[2]):\n",
    "                for y in range(self.picture_image.shape[1]):\n",
    "                    x_p = np.random.randint(0, self.picture_image.shape[2] - 1)\n",
    "                    y_p = np.random.randint(0, self.picture_image.shape[1] - 1)\n",
    "                    self.styled_image[0, y, x, :] = \\\n",
    "                        self.style_image[0, y_p, x_p, :] if canvas == 'random_from_style' \\\n",
    "                        else self.picture_image[0, y_p, x_p, :]\n",
    "\n",
    "        bounds = None\n",
    "\n",
    "        # Set bounds if the optimization method supports them\n",
    "        if optimization_method in ('L-BFGS-B', 'TNC', 'SLSQP'):\n",
    "            bounds = np.ndarray(shape=(self.styled_image.flatten().shape[0], 2))\n",
    "            bounds[:, 0] = -128.0\n",
    "            bounds[:, 1] = 128.0\n",
    "\n",
    "        print('Starting optimization with method: %r' % optimization_method)\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            self.iteration += 1\n",
    "\n",
    "            if self.verbose:\n",
    "                print('Starting iteration: %d' % self.iteration)\n",
    "\n",
    "            minimize(fun=self.loss, x0=self.styled_image.flatten(), jac=self.loss_gradient,\n",
    "                     callback=self.callback, bounds=bounds, method=optimization_method)\n",
    "\n",
    "            self.save_image(self.styled_image)\n",
    "\n",
    "    def loss(self, image):\n",
    "        outputs = self.get_convnet_output([image.reshape(self.e_image_shape).astype(K.floatx())])\n",
    "        outputs.append(image.reshape(self.e_image_shape).astype(K.floatx()))\n",
    "\n",
    "        v_loss = self.loss_function(outputs)[0]\n",
    "\n",
    "        if self.verbose:\n",
    "            print('\\tLoss: %.2f' % v_loss)\n",
    "\n",
    "        # Check whether loss has become NaN\n",
    "        if math.isnan(v_loss):\n",
    "            print('NaN Loss function value')\n",
    "\n",
    "        return v_loss\n",
    "\n",
    "    def loss_gradient(self, image):\n",
    "        return np.array(self.loss_function_gradient([image.reshape(self.e_image_shape).astype(K.floatx())])).\\\n",
    "            astype('float64').flatten()\n",
    "\n",
    "    def callback(self, image):\n",
    "        self.step += 1\n",
    "        self.styled_image = image.copy()\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Optimization step: %d/%d' % (self.step, self.iteration))\n",
    "\n",
    "        if self.step == 1 or self.step % self.save_every_n_steps == 0:\n",
    "            self.save_image(image)\n",
    "\n",
    "    def save_image(self, image):\n",
    "        imsave(self.destination_folder + 'img_' + str(self.step) + '_' + str(self.iteration) + '.jpg',\n",
    "               self.post_process_image(image.reshape(self.e_image_shape).copy()))\n",
    "\n",
    "    @staticmethod\n",
    "    def gramian(filters):\n",
    "        c_filters = K.batch_flatten(K.permute_dimensions(K.squeeze(filters, axis=0), pattern=(2, 0, 1)))\n",
    "        return K.dot(c_filters, K.transpose(c_filters))\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_process_image(image):\n",
    "        return preprocess_input(image)\n",
    "\n",
    "    @staticmethod\n",
    "    def post_process_image(image):\n",
    "        image[:, :, :, 0] += 103.939\n",
    "        image[:, :, :, 1] += 116.779\n",
    "        image[:, :, :, 2] += 123.68\n",
    "        return np.clip(image[:, :, :, ::-1], 0, 255).astype('uint8')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "VGG_Convnet\n",
      "Loading picture: profile.jpg (582x874)\n",
      "Loading style image: monet.jpg (660x504)\n",
      "Resizing style image to match picture size: (582x874)\n",
      "Compiling loss and gradient functions\n",
      "Starting optimization with method: 'TNC'\n",
      "Starting iteration: 1\n",
      "\tLoss: 45012180008960.00\n",
      "\tLoss: 45012175814656.00\n",
      "\tLoss: 42640540172288.00\n",
      "\tLoss: 42640527589376.00\n",
      "\tLoss: 42640510812160.00\n",
      "\tLoss: 42640485646336.00\n",
      "\tLoss: 42640460480512.00\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "neural_styler = NeuralStyler(content_image_path='profile.jpg',\n",
    "                                 style_image_path='monet.jpg',\n",
    "\n",
    "                                 # If you have a local copy of Keras VGG16/19 weights\n",
    "                                 # weights_filepath='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "                                 Content_loss_function_weight=0.4,\n",
    "                                 Style_loss_function_weight=0.6,\n",
    "                                 verbose=True,\n",
    "                                 content_layer='block4_conv1',\n",
    "                                 style_layers=('block1_conv1',\n",
    "                                               'block2_conv1',\n",
    "                                               'block3_conv1',\n",
    "                                               'block4_conv1',\n",
    "                                               'block5_conv1'))\n",
    "\n",
    "    # Create styled image\n",
    "    #neural_styler.fit(canvas='picture', optimization_method='L-BFGS-B')\n",
    "    # or\n",
    "    # neural_styler.fit(canvas='picture', optimization_method='CG')\n",
    "\n",
    "    # Try also\n",
    "    #\n",
    "neural_styler.fit(canvas='random_from_style', optimization_method='TNC')\n",
    "    # and\n",
    "    # neural_styler.fit(canvas='style')\n",
    "    #\n",
    "    # with different optimization algorithms (CG, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
